{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import load_model\n",
    "from pandas.io.parsers import read_csv\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(test=False):\n",
    "    \"\"\"\n",
    "    Loads data from FTEST if *test* is True, otherwise from FTRAIN.\n",
    "    The files are in a ../data/kaggle_facialKeyPointDetection/ directory\n",
    "    \"\"\"\n",
    "    \n",
    "    FTRAIN = '../data/kaggle_facialKeyPointDetection/training.csv'\n",
    "    FTEST = '../data/kaggle_facialKeyPointDetection/test.csv'\n",
    "    \n",
    "    fname = FTEST if test else FTRAIN\n",
    "    \n",
    "    # Load dataframes\n",
    "    df = read_csv(os.path.expanduser(fname))\n",
    "    \n",
    "    # Image column has space separated pixel values - converting values to numpy arrays\n",
    "    df['Image'] = df['Image'].apply(lambda im: np.fromstring(im, sep=' '))\n",
    "\n",
    "    # Drop rows that have missing values in them\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Scale pixel values to [0, 1]\n",
    "    X = np.vstack(df['Image'].values) / 255.  \n",
    "    X = X.astype(np.float32)\n",
    "    \n",
    "    # return images as 96 x 96 x 1\n",
    "    X = X.reshape(-1, 96, 96, 1)\n",
    "\n",
    "    if not test:\n",
    "        y = df[df.columns[:-1]].values\n",
    "        y = (y - 48) / 48  # scale target coordinates to [-1, 1]\n",
    "        X, y = shuffle(X, y, random_state=42)  # shuffle train data\n",
    "        y = y.astype(np.float32)\n",
    "    else:\n",
    "        y = None\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Facial landmark CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Dropout\n",
    "from keras.layers import Flatten, Dense\n",
    "from keras.optimizers import SGD, RMSprop, Adagrad, Adadelta, Adam, Adamax, Nadam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_my_CNN_model_architecture():\n",
    "    '''\n",
    "    The network accepts a 96x96 grayscale image as input and returns a vector with 30 entries\n",
    "    corresponding to the predicted (horizontal and vertical) locations of 15 facial keypoints\n",
    "    '''\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(32, (5, 5), input_shape=(96,96,1), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Convolution2D(30, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(30))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Util - Calibrate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_my_CNN_model(model, optimizer, loss, metrics):\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_my_CNN_model(model, X_train, y_train):\n",
    "    return model.fit(X_train, y_train, epochs=100, batch_size=200, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = get_my_CNN_model_architecture()\n",
    "\n",
    "# Compiling the CNN model with an appropriate optimizer and loss and metrics\n",
    "compile_my_CNN_model(my_model, optimizer = 'adam', loss = 'mean_squared_error', metrics = ['accuracy'])\n",
    "\n",
    "# Training the model\n",
    "hist = train_my_CNN_model(my_model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.save('../model/my-facial_landmark-model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add filter to image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_image = cv2.imread('../../zzz/official-docs/myPhoto.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert image to gray scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(my_image, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Face cascade to detect faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('cascades/haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detect faces using Haar cascade object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = face_cascade.detectMultiScale(gray, 1.25, 6)\n",
    "faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load facial landmark model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = load_model('../model/my-facial_landmark-model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load filters and select a filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = ['../resources/akshayChandra_selfie-filters/images/sunglasses_1.png', \n",
    "           '../resources/akshayChandra_selfie-filters/images/sunglasses_2.png', \n",
    "           '../resources/akshayChandra_selfie-filters/images/sunglasses_3.jpg', \n",
    "           '../resources/akshayChandra_selfie-filters/images/sunglasses_4.png', \n",
    "           '../resources/akshayChandra_selfie-filters/images/sunglasses_5.jpg', \n",
    "           '../resources/akshayChandra_selfie-filters/images/sunglasses_6.png']\n",
    "filterIndex = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get facial landmarks in ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over all the faces found in the frame\n",
    "\n",
    "for (x, y, w, h) in faces:\n",
    "    \n",
    "    # Make the faces ready for the model (normalize and resize)\n",
    "    gray_face = gray[y:y+h, x:x+w]\n",
    "    color_face = my_image[y:y+h, x:x+w]\n",
    "    my_image_filter = my_image.copy()\n",
    "\n",
    "    # Normalize to match the input format of the model - Range of pixel to [0, 1]\n",
    "    gray_normalized = gray_face / 255\n",
    "\n",
    "    # Resize it to 96x96 to match the input format of the model\n",
    "    original_shape = gray_face.shape # A Copy for future reference\n",
    "    face_resized = cv2.resize(gray_normalized, (96, 96), interpolation = cv2.INTER_AREA)\n",
    "    face_resized_copy = face_resized.copy()\n",
    "    face_resized = face_resized.reshape(1, 96, 96, 1)\n",
    "\n",
    "    # Predict the keypoints using the model\n",
    "    keypoints = my_model.predict(face_resized)\n",
    "\n",
    "    # De-Normalize the keypoints values\n",
    "    keypoints = keypoints * 48 + 48\n",
    "\n",
    "    # Map the Keypoints back to the original image\n",
    "    face_resized_color = cv2.resize(color_face, (96, 96), interpolation = cv2.INTER_AREA)\n",
    "    face_resized_color2 = np.copy(face_resized_color)\n",
    "\n",
    "    # Pair the keypoints together - (x1, y1)\n",
    "    points = []\n",
    "    for i, co in enumerate(keypoints[0][0::2]):\n",
    "        points.append((co, keypoints[0][1::2][i]))\n",
    "        \n",
    "    # Add FILTER to the frame\n",
    "    sunglasses = cv2.imread(filters[filterIndex], cv2.IMREAD_UNCHANGED)\n",
    "    sunglass_width = int((points[7][0]-points[9][0])*1.1)\n",
    "    sunglass_height = int((points[10][1]-points[8][1])/1.1)\n",
    "    sunglass_resized = cv2.resize(sunglasses, \n",
    "                                  (sunglass_width, sunglass_height), interpolation = cv2.INTER_CUBIC)\n",
    "    transparent_region = sunglass_resized[:,:,:3] != 0\n",
    "    face_resized_color[int(points[9][1]):int(points[9][1])+sunglass_height, \n",
    "                       int(points[9][0]):\n",
    "                       int(points[9][0]) + \n",
    "                       sunglass_width,:][transparent_region] = sunglass_resized[:,:,:3][transparent_region]\n",
    "\n",
    "    # Resize the face_resized_color image back to its original shape\n",
    "    my_image[y:y+h, x:x+w] = cv2.resize(face_resized_color, original_shape, interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "    # Add KEYPOINTS to the my_image_filter\n",
    "    for keypoint in points:\n",
    "        cv2.circle(face_resized_color2, keypoint, 1, (0,255,0), 1)\n",
    "\n",
    "    my_image_filter[y:y+h, x:x+w] = cv2.resize(face_resized_color2, original_shape, \n",
    "                                               interpolation = cv2.INTER_CUBIC)\n",
    "    \n",
    "    \n",
    "    # If the 'q' key is pressed, stop the loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the frame and the my_image_filter\n",
    "cv2.imshow(\"Selfie Filters\", my_image)\n",
    "cv2.imshow(\"Facial Keypoints\", my_image_filter)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
